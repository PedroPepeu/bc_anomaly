{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2b3ad90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2353242e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando e processando KDDTrain+.txt...\n"
     ]
    }
   ],
   "source": [
    "COLUMN_NAMES = [\n",
    "    'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes',\n",
    "    'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in',\n",
    "    'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations',\n",
    "    'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login',\n",
    "    'is_guest_login', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate',\n",
    "    'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate',\n",
    "    'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count',\n",
    "    'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
    "    'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate',\n",
    "    'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'class', 'difficulty'\n",
    "]\n",
    "CATEGORICAL_FEATURES = ['protocol_type', 'service', 'flag']\n",
    "LABEL_COLUMN = 'class'\n",
    "NORMAL_CLASS_NAME = 'normal'\n",
    "\n",
    "def preprocess(df):\n",
    "    X = df.drop(columns=[LABEL_COLUMN, 'difficulty'])\n",
    "    y_labels = df[LABEL_COLUMN]\n",
    "    \n",
    "    y = np.where(y_labels == NORMAL_CLASS_NAME, 1, -1)\n",
    "    \n",
    "    X_dummies = pd.get_dummies(X, columns=CATEGORICAL_FEATURES, dummy_na=False)\n",
    "        \n",
    "    return X_dummies, y\n",
    "\n",
    "print(\"Carregando e processando KDDTrain+.txt...\")\n",
    "try:\n",
    "    df_train = pd.read_csv('KDDTrain+.txt', header=None, names=COLUMN_NAMES)\n",
    "except FileNotFoundError:\n",
    "    print(\"ERRO: Arquivo 'KDDTrain+.txt' não encontrado.\")\n",
    "    exit()\n",
    "\n",
    "X_train_df, y_train = preprocess(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64510c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando dados de data_1.csv...\n",
      "Dados carregados em 0.37 segundos.\n",
      "Total de linhas carregadas: 200000\n",
      "\n",
      "Distribuição das classes (coluna 'attack'):\n",
      "attack\n",
      "1    198779\n",
      "0      1221\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69844/691213724.py:5: DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(FILE_PATH, nrows=NROWS_FOR_TESTING)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Carregando dados de {FILE_PATH}...\")\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "  df = pd.read_csv(FILE_PATH, nrows=NROWS_FOR_TESTING)\n",
    "except FileNotFoundError:\n",
    "  print(f\"ERRO: Arquivo não encontrado em '{FILE_PATH}'.\")\n",
    "  exit()\n",
    "except Exception as e:\n",
    "  print(f\"Erro ao ler o CSV: {e}\")\n",
    "  exit()\n",
    "\n",
    "print(f\"Dados carregados em {time.time() - start_time:.2f} segundos.\")\n",
    "print(f\"Total de linhas carregadas: {len(df)}\")\n",
    "print(f\"\\nDistribuição das classes (coluna '{LABEL_COLUMN}'):\\n{df[LABEL_COLUMN].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79d1c6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Carregando e processando KDDTest+.txt...\n",
      "\n",
      "Alinhando colunas de treino e teste...\n",
      "Formato Treino: (125973, 122), Formato Teste Alinhado: (22544, 122)\n",
      "Escalonando dados...\n",
      "\n",
      "Treinando o modelo IsolationForest...\n",
      "Taxa de contaminação (anomalias) no treino: 0.4654\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCarregando e processando KDDTest+.txt...\")\n",
    "try:\n",
    "    df_test = pd.read_csv('KDDTest+.txt', header=None, names=COLUMN_NAMES)\n",
    "except FileNotFoundError:\n",
    "    print(\"ERRO: Arquivo 'KDDTest+.txt' não encontrado.\")\n",
    "    exit()\n",
    "\n",
    "X_test_df, y_test = preprocess(df_test)\n",
    "\n",
    "print(\"\\nAlinhando colunas de treino e teste...\")\n",
    "\n",
    "train_cols = X_train_df.columns\n",
    "\n",
    "X_test_aligned = X_test_df.reindex(columns=train_cols, fill_value=0)\n",
    "\n",
    "print(f\"Formato Treino: {X_train_df.shape}, Formato Teste Alinhado: {X_test_aligned.shape}\")\n",
    "if X_train_df.shape[1] != X_test_aligned.shape[1]:\n",
    "     print(\"ERRO: Alinhamento falhou!\")\n",
    "     exit()\n",
    "\n",
    "print(\"Escalonando dados...\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_df)\n",
    "X_test_scaled = scaler.transform(X_test_aligned) \n",
    "\n",
    "print(\"\\nTreinando o modelo IsolationForest...\")\n",
    "start_time = time.time()\n",
    "\n",
    "contamination_rate = (y_train == -1).sum() / len(y_train)\n",
    "print(f\"Taxa de contaminação (anomalias) no treino: {contamination_rate:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1af93fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinamento concluído em 20.81 segundos.\n",
      "\n",
      "Avaliando o modelo no conjunto de TESTE...\n"
     ]
    }
   ],
   "source": [
    "model = IsolationForest(\n",
    "    n_estimators=100,\n",
    "    contamination=contamination_rate,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model.fit(X_train_scaled) \n",
    "print(f\"Treinamento concluído em {time.time() - start_time:.2f} segundos.\")\n",
    "\n",
    "print(\"\\nAvaliando o modelo no conjunto de TESTE...\")\n",
    "y_pred = model.predict(X_test_scaled) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "449657bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Criando conjunto de treino com Undersampling...\n",
      "Amostras de treino 'Normal': 855\n",
      "Amostras de treino 'Anomalia': 139145\n",
      "Novo conjunto de treino: 30855 amostras\n",
      "Taxa de contaminação NO TREINO: 0.9723\n"
     ]
    }
   ],
   "source": [
    "# --- 5. !! NOVA ESTRATÉGIA: UNDERSAMPLING PARA O TREINO !! ---\n",
    "print(\"\\nCriando conjunto de treino com Undersampling...\")\n",
    "\n",
    "# 5.1. Separar dados de treino por classe\n",
    "X_train_normal = X_train[y_train == 1]\n",
    "y_train_normal = y_train[y_train == 1]\n",
    "X_train_anomaly = X_train[y_train == -1]\n",
    "y_train_anomaly = y_train[y_train == -1]\n",
    "\n",
    "print(f\"Amostras de treino 'Normal': {len(X_train_normal)}\")\n",
    "print(f\"Amostras de treino 'Anomalia': {len(X_train_anomaly)}\")\n",
    "\n",
    "# 5.2. Definir o tamanho da amostra de anomalias\n",
    "# Vamos pegar um número bem menor de anomalias, mas ainda dominante\n",
    "# Ex: 30.000 (você pode ajustar esse número)\n",
    "N_ANOMALY_SAMPLES = 30000 \n",
    "if N_ANOMALY_SAMPLES > len(X_train_anomaly):\n",
    "    N_ANOMALY_SAMPLES = len(X_train_anomaly) # Caso tenha menos\n",
    "\n",
    "# 5.3. Fazer a amostragem aleatória (sem reposição)\n",
    "np.random.seed(42) # para reprodutibilidade\n",
    "indices = np.random.choice(len(X_train_anomaly), N_ANOMALY_SAMPLES, replace=False)\n",
    "X_train_anomaly_sampled = X_train_anomaly[indices]\n",
    "y_train_anomaly_sampled = y_train_anomaly[indices]\n",
    "\n",
    "# 5.4. Criar o novo conjunto de treino (balanceado)\n",
    "X_train_new = np.concatenate([X_train_normal, X_train_anomaly_sampled])\n",
    "y_train_new = np.concatenate([y_train_normal, y_train_anomaly_sampled])\n",
    "\n",
    "print(f\"Novo conjunto de treino: {len(X_train_new)} amostras\")\n",
    "\n",
    "# 5.5. Calcular a *nova* taxa de contaminação para este conjunto\n",
    "contamination_rate = (y_train_new == -1).sum() / len(y_train_new)\n",
    "print(f\"Taxa de contaminação NO TREINO: {contamination_rate:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c99fb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Treinando o modelo IsolationForest...\n",
      "Treinamento concluído em 0.43 segundos.\n"
     ]
    }
   ],
   "source": [
    "# --- 5. TREINAR O ISOLATION FOREST ---\n",
    "print(\"\\nTreinando o modelo IsolationForest...\")\n",
    "start_time = time.time()\n",
    "\n",
    "model = IsolationForest(\n",
    "  n_estimators=100,\n",
    "  contamination='auto',\n",
    "  random_state=42,\n",
    "  n_jobs=-1\n",
    ")\n",
    "\n",
    "model.fit(X_train_new)\n",
    "\n",
    "print(f\"Treinamento concluído em {time.time() - start_time:.2f} segundos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e381355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Relatório de Classificação (NSL-KDD):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Anomalia (-1)       0.81      0.82      0.81     12833\n",
      "   Normal (1)       0.76      0.74      0.75      9711\n",
      "\n",
      "     accuracy                           0.79     22544\n",
      "    macro avg       0.78      0.78      0.78     22544\n",
      " weighted avg       0.79      0.79      0.79     22544\n",
      "\n",
      "\n",
      "Matriz de Confusão (NSL-KDD):\n",
      "[[10533  2300]\n",
      " [ 2532  7179]]\n",
      "Formato: [ [Verdadeiro Anomalia, Falso Normal], [Falso Anomalia, Verdadeiro Normal] ]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRelatório de Classificação (NSL-KDD):\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Anomalia (-1)', 'Normal (1)']))\n",
    "print(\"\\nMatriz de Confusão (NSL-KDD):\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(\"Formato: [ [Verdadeiro Anomalia, Falso Normal], [Falso Anomalia, Verdadeiro Normal] ]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e87d445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Salvando o modelo treinado...\n",
      "Modelo salvo como 'iforest_detector_model.joblib'\n",
      "Scaler salvo como 'data_scaler.joblib'\n",
      "\n",
      "Script concluído!\n"
     ]
    }
   ],
   "source": [
    "# --- 9. SALVAR O MODELO ---\n",
    "print(\"\\nSalvando o modelo treinado...\")\n",
    "joblib.dump(model, 'iforest_nslkdd_model.joblib')\n",
    "joblib.dump(scaler, 'data_scaler_nslkdd.joblib')\n",
    "print(\"Modelo salvo como 'iforest_nslkdd_model.joblib'\")\n",
    "print(\"\\nScript concluído!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e721d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mvp-env (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
